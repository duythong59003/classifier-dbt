{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b45b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eeef3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoang\\AppData\\Local\\Temp\\ipykernel_6332\\422718307.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"SELECT * FROM public.stg_document\", con=db_connection)\n"
     ]
    }
   ],
   "source": [
    "username = os.getenv('postgreUsername')\n",
    "password = os.getenv('postgrePassword')\n",
    "DATABASE_URL = f\"postgresql://{username}:{password}@localhost:5432/news\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "session = sessionmaker(bind=engine)\n",
    "\n",
    "\n",
    "query = \"SELECT * FROM stg_document\"\n",
    "\n",
    "db_connection = psycopg2.connect(\n",
    "    host='localhost',\n",
    "    database=\"news\",\n",
    "    user=username,\n",
    "    password=password\n",
    ")\n",
    "cursor = db_connection.cursor()\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM public.stg_document\", con=db_connection)\n",
    "\n",
    "cursor.close()\n",
    "# db_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f69d0155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>$1m payoff for former Shell boss  Shell is to ...</td>\n",
       "      <td>business</td>\n",
       "      <td>1424</td>\n",
       "      <td>241</td>\n",
       "      <td>2025-08-04 12:10:39.140625+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>$1m payoff for former Shell boss  Shell is to ...</td>\n",
       "      <td>business</td>\n",
       "      <td>1424</td>\n",
       "      <td>241</td>\n",
       "      <td>2025-08-04 12:10:39.140625+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>$1m payoff for former Shell boss  Shell is to ...</td>\n",
       "      <td>business</td>\n",
       "      <td>1424</td>\n",
       "      <td>241</td>\n",
       "      <td>2025-08-04 12:10:39.140625+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&amp;#163;1.8m indecency fine for Viacom  Media gi...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1470</td>\n",
       "      <td>238</td>\n",
       "      <td>2025-08-04 12:10:39.140625+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>&amp;#163;1.8m indecency fine for Viacom  Media gi...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1470</td>\n",
       "      <td>238</td>\n",
       "      <td>2025-08-04 12:10:39.140625+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               data   actual_label  \\\n",
       "0   1  $1m payoff for former Shell boss  Shell is to ...       business   \n",
       "1   2  $1m payoff for former Shell boss  Shell is to ...       business   \n",
       "2   3  $1m payoff for former Shell boss  Shell is to ...       business   \n",
       "3   4  &#163;1.8m indecency fine for Viacom  Media gi...  entertainment   \n",
       "4   5  &#163;1.8m indecency fine for Viacom  Media gi...  entertainment   \n",
       "\n",
       "   text_length  word_count                     processed_at  \n",
       "0         1424         241 2025-08-04 12:10:39.140625+00:00  \n",
       "1         1424         241 2025-08-04 12:10:39.140625+00:00  \n",
       "2         1424         241 2025-08-04 12:10:39.140625+00:00  \n",
       "3         1470         238 2025-08-04 12:10:39.140625+00:00  \n",
       "4         1470         238 2025-08-04 12:10:39.140625+00:00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7069810d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>$1m payoff for former Shell boss  Shell is to ...</td>\n",
       "      <td>business</td>\n",
       "      <td>1424</td>\n",
       "      <td>241</td>\n",
       "      <td>2025-08-04 12:10:39.140625+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&amp;#163;1.8m indecency fine for Viacom  Media gi...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1470</td>\n",
       "      <td>238</td>\n",
       "      <td>2025-08-04 12:10:39.140625+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2004: An Irish Athletics Year  2004 wont be re...</td>\n",
       "      <td>sport</td>\n",
       "      <td>4240</td>\n",
       "      <td>733</td>\n",
       "      <td>2025-08-04 12:10:39.140625+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2D Metal Slug offers retro fun  Like some dril...</td>\n",
       "      <td>tech</td>\n",
       "      <td>1771</td>\n",
       "      <td>319</td>\n",
       "      <td>2025-08-04 12:10:39.140625+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Aaliyah claim dismissed by court  Late R&amp;B sta...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1101</td>\n",
       "      <td>197</td>\n",
       "      <td>2025-08-04 12:10:39.140625+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               data   actual_label  \\\n",
       "0    1  $1m payoff for former Shell boss  Shell is to ...       business   \n",
       "3    4  &#163;1.8m indecency fine for Viacom  Media gi...  entertainment   \n",
       "6    7  2004: An Irish Athletics Year  2004 wont be re...          sport   \n",
       "9   10  2D Metal Slug offers retro fun  Like some dril...           tech   \n",
       "15  16  Aaliyah claim dismissed by court  Late R&B sta...  entertainment   \n",
       "\n",
       "    text_length  word_count                     processed_at  \n",
       "0          1424         241 2025-08-04 12:10:39.140625+00:00  \n",
       "3          1470         238 2025-08-04 12:10:39.140625+00:00  \n",
       "6          4240         733 2025-08-04 12:10:39.140625+00:00  \n",
       "9          1771         319 2025-08-04 12:10:39.140625+00:00  \n",
       "15         1101         197 2025-08-04 12:10:39.140625+00:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=\"data\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6634dfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1m payoff for former Shell boss  Shell is to p...\n",
       "3     16318m indecency fine for Viacom  Media giant ...\n",
       "6     2004 An Irish Athletics Year  2004 wont be rem...\n",
       "9     2D Metal Slug offers retro fun  Like some dril...\n",
       "15    Aaliyah claim dismissed by court  Late RB star...\n",
       "Name: data_regex, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove punctuation: not a word or whitespace\n",
    "df['data_regex'] = df['data'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "#remove email\n",
    "df['data_regex'] = df['data_regex'].apply(lambda x: re.sub(r'\\S+@\\S+', '', x))\n",
    "#remove url\n",
    "df['data_regex'] = df['data_regex'].apply(lambda x: re.sub(r'http\\S+|www\\S+|https\\S+', '', x))\n",
    "df['data_regex'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6b2352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [1m, payoff, for, former, Shell, boss, Shell, ...\n",
       "3     [16318m, indecency, fine, for, Viacom, Media, ...\n",
       "6     [2004, An, Irish, Athletics, Year, 2004, wont,...\n",
       "9     [2D, Metal, Slug, offers, retro, fun, Like, so...\n",
       "15    [Aaliyah, claim, dismissed, by, court, Late, R...\n",
       "Name: data_tokenize, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize sentence word by word\n",
    "df['data_tokenize'] = df['data_regex'].apply(word_tokenize)\n",
    "df['data_tokenize'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da53119e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"isn't\", 's', 'up', 'd', \"it'd\", \"they'd\", 'ourselves', 'being', 'about', \"hasn't\", 'should', 've', \"i'm\", 'having', 'or', 'below', 'her', 'not', 're', 'him', 'so', 'other', \"that'll\", 'were', 'you', 'during', 'each', \"doesn't\", 'be', 'are', 'its', 'them', 'doesn', 'when', \"they're\", 'my', 'only', \"we'll\", 'by', 'don', 'wouldn', 'how', 'over', 'any', 'he', 'didn', \"mustn't\", 'nor', \"he's\", 'all', 'has', 'll', 'y', \"aren't\", \"you've\", 'while', 'just', 'than', 'at', 'yours', 'out', 'itself', 'himself', \"you're\", 'too', 'couldn', 'your', 'once', 'these', 'yourselves', 'until', 'i', 'was', 'his', 'that', 'and', 'does', 'here', 'but', \"it'll\", \"wouldn't\", 'have', 'no', 'between', 'same', 'down', 'the', \"needn't\", 'yourself', 'herself', 'm', 'it', \"i've\", 'mustn', \"you'd\", 'after', \"should've\", 'theirs', \"haven't\", 'most', 'some', 'whom', 'off', \"he'll\", 'had', 'this', 'through', 'on', 'an', 'as', 'me', \"she'd\", 'ain', 'myself', \"she's\", 'wasn', 'with', 'in', 'because', 'they', \"couldn't\", \"we'd\", 'aren', 'won', 'haven', 'both', 'very', 't', 'for', \"weren't\", \"don't\", 'do', 'against', 'hadn', \"we've\", 'before', 'themselves', 'ma', 'few', 'further', 'o', \"won't\", 'what', 'will', \"we're\", \"they'll\", \"you'll\", 'ours', 'hasn', 'of', 'am', \"shouldn't\", 'doing', 'more', 'weren', 'hers', 'needn', \"he'd\", \"i'd\", 'she', 'now', 'did', 'from', 'above', 'can', 'our', 'mightn', 'into', \"mightn't\", 'which', 'if', \"i'll\", 'again', 'their', \"they've\", 'we', 'is', \"wasn't\", 'why', \"hadn't\", 'who', 'a', 'been', \"it's\", 'shouldn', 'such', 'own', 'there', 'under', 'those', 'where', \"didn't\", \"she'll\", 'isn', \"shan't\", 'shan', 'then', 'to'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hoang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords1 = set(stopwords.words('english'))\n",
    "print(stopwords1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e334e1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [1m, payoff, former, Shell, boss, Shell, pay, ...\n",
       "3     [16318m, indecency, fine, Viacom, Media, giant...\n",
       "6     [2004, Irish, Athletics, Year, 2004, wont, rem...\n",
       "9     [2D, Metal, Slug, offers, retro, fun, Like, dr...\n",
       "15    [Aaliyah, claim, dismissed, court, Late, RB, s...\n",
       "Name: data_tokenize, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove stopwords\n",
    "df['data_tokenize'] = df['data_tokenize'].apply(\n",
    "    lambda tokens: [word for word in tokens if word.lower() not in stopwords1]\n",
    ")\n",
    "\n",
    "df['data_tokenize'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "556dc5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.97      0.97      0.97       101\n",
      "entertainment       0.99      0.95      0.97        79\n",
      "     politics       0.98      0.98      0.98        87\n",
      "        sport       0.99      1.00      0.99        96\n",
      "         tech       0.95      0.98      0.97        63\n",
      "\n",
      "     accuracy                           0.98       426\n",
      "    macro avg       0.98      0.98      0.98       426\n",
      " weighted avg       0.98      0.98      0.98       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['data_tokenize'] = df['data_tokenize'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# Feature & label selection\n",
    "X = df['data_tokenize']  # should be a column of strings (not lists!)\n",
    "y = df['actual_label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=3000,\n",
    "    stop_words='english',\n",
    "    lowercase=True,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "# TF-IDF transformation\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions & Evaluation\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b2531e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../checkpoint/tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(classifier, '../checkpoint/tfidf_classifier.pkl')\n",
    "joblib.dump(vectorizer, '../checkpoint/tfidf_vectorizer.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
